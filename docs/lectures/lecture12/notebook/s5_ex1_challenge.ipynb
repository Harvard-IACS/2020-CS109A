{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "\n",
    "**Exercise: 2 - Variation of coefficients**\n",
    "\n",
    "# Description\n",
    "\n",
    "The goal of this exercise is to understand the variation of the coefficients of the predictors with varying values of regularization parameter in Lasso and Ridge regularization.\n",
    "\n",
    "Below is a sample plot for Ridge ($L_2$ regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/image2.png\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "- Read the dataset `bateria_train.csv` and assign the predictor and response variables.\n",
    "- The predictor is the `Spreading factor` and the response variable is the `Perc_population`\n",
    "- Use a maximum degree of 7 to make polynomial features and make a new predictor `x_poly`\n",
    "- Make a list of alpha values.\n",
    "- For each value of $\\alpha$:\n",
    "    - Fit a multi-linear regression using $L_2$ regularization\n",
    "    - Compute the coefficient of the predictors and store to the plot later\n",
    "- Make a plot of the coefficients along with the alpha values\n",
    "- Make a new alpha list as per the code in the exercise\n",
    "- Implement Lasso regularization by repeating the above steps for each value of alpha\n",
    "- make another plot of the coefficients along with the new alpha values\n",
    "\n",
    "# Hints:\n",
    "\n",
    "\n",
    "<a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.transpose.html\" target=\"_blank\">np.transpose()</a> : Reverse or permute the axes of an array; returns the modified array\n",
    " \n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html\" target=\"_blank\">sklearn.normalize()</a> : Scales input vectors individually to the unit norm (vector length)\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\" target=\"_blank\">sklearn.train_test_split()</a> : Splits the data into random train and test subsets\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\" target=\"_blank\">sklearn.PolynomialFeatures()</a> : Generates a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\" target=\"_blank\">sklearn.fit_transform()</a> : Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" target=\"_blank\">sklearn.LinearRegression()</a> : LinearRegression fits a linear model\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.fit\" target=\"_blank\">sklearn.fit()</a> : Fits the linear model to the training data\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.predict\" target=\"_blank\">sklearn.predict()</a> : Predict using the linear modReturns the coefficient of the predictors in the model.\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\" target=\"_blank\">mean_squared_error()</a> : Mean squared error regression loss\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" target=\"_blank\">sklearn.coef_</a> : Returns the coefficients of the predictors\n",
    "\n",
    "<a href=\"https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.pyplot.subplots.html\" target=\"_blank\">plt.subplots()</a> : Create a figure and a set of subplots\n",
    "\n",
    "<a href=\"https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.axes.Axes.barh.html\" target=\"_blank\">ax.barh()</a> : Make a horizontal bar plot\n",
    "\n",
    "<a href=\"https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.axes.Axes.set_xlim.html\" target=\"_blank\">ax.set_xlim()</a> : Sets the x-axis view limits\n",
    "\n",
    "<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\" target=\"_blank\">sklearn.Lasso()</a> : Linear Model trained with L1 prior as a regularizer\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\" target=\"_blank\">sklearn.Ridge()</a> : Linear least squares with L2 regularization\n",
    "\n",
    "<a href=\"https://docs.python.org/3.3/library/functions.html#zip\" target=\"_blank\">zip()</a> : Makes an iterator that aggregates elements from each of the iterables.\n",
    "\n",
    "**Note: This exercise is auto-graded and you can try multiple attempts.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell for more readable visuals \n",
    "\n",
    "large = 22; med = 16; small = 10\n",
    "params = {'axes.titlesize': large,\n",
    "          'legend.fontsize': med,\n",
    "          'figure.figsize': (16, 10),\n",
    "          'axes.labelsize': med,\n",
    "          'axes.titlesize': med,\n",
    "          'axes.linewidth': 2,\n",
    "          'xtick.labelsize': med,\n",
    "          'ytick.labelsize': med,\n",
    "          'figure.titlesize': large}\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rcParams.update(params)\n",
    "#sns.set_style(\"white\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file \"bacteria_train.csv\" as a dataframe\n",
    "# The file is the same as your homework 2\n",
    "\n",
    "df = pd.read_csv(\"bacteria_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a quick look of your dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the predictor ('Spreading_factor') and the response ('Perc_population') values as the variables 'x' and 'y'\n",
    "\n",
    "x, y  = df[[___]], df[___]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the number of polynomial features as per the maximum degree\n",
    "\n",
    "maxdeg = 4\n",
    "x_poly = PolynomialFeatures(___).fit_transform(___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a list of alpha values ranging from 10 to 120 with 1000 points between them\n",
    "\n",
    "alpha_list = np.linspace(___,___,___)\n",
    "len(alpha_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_ridge_fit) ###\n",
    "# Make an empty list called coeff_list and for each alpha value, compute the coefficients and add it to coeff_list\n",
    "coeff_list = []\n",
    "\n",
    "\n",
    "#Now, you will implement the ridge regularisation for each alpha value, make sure you set Normalize=True\n",
    "\n",
    "for i in alpha_list:\n",
    "\n",
    "    ridge_reg = Ridge(alpha=___,normalize=___)\n",
    "\n",
    "    #Fit on the entire data because we just want to see the trend of the coefficients\n",
    "\n",
    "    ridge_reg.fit(___, ___)\n",
    "    \n",
    "    # Append the coeff_list with the coefficients of the model\n",
    "    \n",
    "    coeff_list.append(___)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take the transpose of the list to get the variation in the coefficient values per degree\n",
    "\n",
    "trend = np.array(coeff_list).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the code below to plot the variation of the coefficients as per the alpha value\n",
    "\n",
    "# Just adding some nice colors. make sure to comment this cell out if you plan to use degree more than 7\n",
    "colors = ['#5059E8','#9FC131FF','#D91C1C','#9400D3','#FF2F92','#336600','black']\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "for i in range(maxdeg):\n",
    "    ax.plot(alpha_list,np.abs(trend[i+1]),color=colors[i],alpha = 0.9,label = f'Degree {i+1}',lw=2.2)\n",
    "    ax.legend(loc='best',fontsize=10)\n",
    "    ax.set_xlabel(r'$\\alpha$ values', fontsize=20)\n",
    "    ax.set_ylabel(r'$\\beta$ values', fontsize=20)\n",
    "\n",
    "fig.suptitle(r'Ridge ($L_2$) Regression');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the results of Ridge regression with the Lasso variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a list of alpha values ranging from 1e-4 to 1e-1 with 1000 points between them\n",
    "\n",
    "alpha_list = np.linspace(___,___,___)\n",
    "len(alpha_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_lasso_fit) ###\n",
    "# Make an empty list called coeff_list and for each alpha value, compute the coefficients and add it to coeff_list\n",
    "coeff_list = []\n",
    "\n",
    "\n",
    "#Now, you will implement the ridge regularisation for each alpha value, again normalize\n",
    "\n",
    "for i in alpha_list:\n",
    "\n",
    "    lasso_reg = Lasso(alpha=i,max_iter=250000,normalize=___)\n",
    "\n",
    "    #Fit on the entire data because we just want to see the trend of the coefficients\n",
    "    \n",
    "    lasso_reg.fit(___, ___)\n",
    "    \n",
    "    # Again append the coeff_list with the coefficients of the model\n",
    "    \n",
    "    coeff_list.append(___)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take the transpose of the list to get the variation in the coefficient values per degree\n",
    "\n",
    "trend = np.array(coeff_list).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use helper code below to plot the variation of the coefficients as per the alpha value\n",
    "\n",
    "colors = ['#5059E8','#9FC131FF','#D91C1C','#9400D3','#FF2F92','#336600','black']\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "for i in range(maxdeg):\n",
    "    ax.plot(alpha_list,np.abs(trend[i+1]),color=colors[i],alpha = 0.9,label = f'Degree {i+1}',lw=2)\n",
    "    ax.legend(loc='best',fontsize=10)\n",
    "    ax.set_xlabel(r'$\\alpha$ values', fontsize=20)\n",
    "    ax.set_ylabel(r'$\\beta$ values', fontsize=20)\n",
    "\n",
    "fig.suptitle(r'Lasso ($L_1$) Regression');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mindchow ðŸ²\n",
    "After marking the exercise, go back and change your maximum degree, and see how your coefficients vary for higher degrees\n",
    "\n",
    "> Remember to hide your `colors` variable to avoid `index error` while plotting coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set the normalize=False. Things look different. Try to think why - Hint think of colinearity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
