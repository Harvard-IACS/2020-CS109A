{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import the main packages\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.inspection import permutation_importance\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import f1_score\n",
                "from sklearn.metrics import roc_auc_score\n",
                "from imblearn.over_sampling import SMOTE\n",
                "from prettytable import PrettyTable\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read the dataset and take a quick look\n",
                "\n",
                "df = pd.read_csv('diabetes.csv')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# On checking the response variable ('Outcome') value counts, you will notice that the number of diabetics are less than the number of non-diabetics \n",
                "\n",
                "df['Outcome'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_imbalance) ###\n",
                "\n",
                "# To estimate the amount of data imbalance, find the ratio of class 1(Diabetics) to the size of the dataset.\n",
                "\n",
                "imbalance_ratio = ___\n",
                "\n",
                "print(f'The percentage of diabetics in the dataset is only {(imbalance_ratio)*100:.2f}%')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Assign the predictor and response variables.\n",
                "\n",
                "# Outcome is the response and all the other columns are the predictors\n",
                "\n",
                "X = ___\n",
                "y = ___"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fix a random_state and split the data into train and validation sets\n",
                "\n",
                "random_state = 22\n",
                "\n",
                "X_train, X_val, y_train,y_val = train_test_split(X,y,train_size = 0.8,random_state =random_state)\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We fix the max_depth variable to 20 for all trees, you can come back and change this to investigate performance of RandomForest\n",
                "\n",
                "max_depth = 20"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Strategy 1 - Vanilla Random Forest\n",
                "\n",
                "- No correction for imbalance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a Random Forest classifier with random_state as above\n",
                "# Set the maximum depth to be max_depth and use 10 estimators\n",
                "random_forest = ___\n",
                "\n",
                "# Fit the model on the training set\n",
                "random_forest.___"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We make predictions on the validation set \n",
                "predictions = ___\n",
                "\n",
                "# We also compute two metrics that better represent misclassification of minority classes i.e `f1 score` and `AUC`\n",
                "# Compute the f1-score and assign it to variable score1\n",
                "score1 = ___\n",
                "\n",
                "# Compute the `auc` and assign it to variable auc1\n",
                "auc1 = ___"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Strategy 2 - Random Forest with class weighting\n",
                "- Balancing the class imbalance in each bootstrap"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a Random Forest classifier with random_state as above\n",
                "\n",
                "# Set the maximum depth to be max_depth and use 10 estimators\n",
                "\n",
                "# Specify `class_weight='balanced_subsample'\n",
                "\n",
                "random_forest = ___\n",
                "\n",
                "# Fit the model on the training data\n",
                "\n",
                "random_forest.___"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We make predictions on the validation set \n",
                "\n",
                "predictions = ___\n",
                "\n",
                "# Again we also compute two metrics that better represent misclassification of minority classes i.e `f1 score` and `AUC`\n",
                "\n",
                "# Compute the f1-score and assign it to variable score2\n",
                "\n",
                "score2 = ___\n",
                "\n",
                "# Compute the `auc` and assign it to variable auc2\n",
                "\n",
                "auc2 = ___"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Strategy 3 - RandomForest with SMOTE\n",
                "- We can use SMOTE along with the previous method to further improve our metrics.\n",
                "- Read more about imblearn's SMOTE [here](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run this cell below to use SMOTE to balance our dataset\n",
                "sm = SMOTE(random_state=3)\n",
                "\n",
                "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
                "\n",
                "#If you now see the shape, you will see that X_train_res has more number of points than X_train\n",
                "\n",
                "print(f'Number of points in balanced dataset is {X_train_res.shape[0]}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Again Define a Random Forest classifier with random_state as above\n",
                "\n",
                "# Set the maximum depth to be max_depth and use 10 estimators\n",
                "\n",
                "# Again specify `class_weight='balanced_subsample'\n",
                "\n",
                "random_forest = ___\n",
                "\n",
                "# Fit the model on the new training data created above with SMOTE \n",
                "\n",
                "random_forest.___"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_smote) ###\n",
                "\n",
                "# We make predictions on the validation set \n",
                "\n",
                "predictions = ___\n",
                "\n",
                "# Again we also compute two metrics that better represent misclassification of minority classes i.e `f1 score` and `AUC`\n",
                "\n",
                "# Compute the f1-score and assign it to variable score3\n",
                "\n",
                "score3 = ___\n",
                "\n",
                "# Compute the `auc` and assign it to variable auc3\n",
                "\n",
                "auc3 = ___"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Finally, we compare the results from the three implementations above\n",
                "\n",
                "# Just run the cells below to see your results\n",
                "\n",
                "pt = PrettyTable()\n",
                "pt.field_names = [\"Strategy\",\"F1 Score\",\"AUC score\"]\n",
                "pt.add_row([\"Random Forest - no correction\",score1,auc1])\n",
                "pt.add_row([\"Random Forest - class weighting\",score2,auc2])\n",
                "pt.add_row([\"Random Forest - SMOTE upsampling\",score3,auc3])\n",
                "print(pt)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Mindchow 🍲\n",
                "\n",
                "- Go back and change the `learning_rate` parameter and `n_estimators` for Adaboost. Do you see an improvement in results?\n",
                "\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        }
    ]
}
