{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Import the libraries\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Read the dataset and take a quick look\n",
                "heart_data = pd.read_csv('data/Heart.csv', index_col=0)\n",
                "heart_data.head()\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Assign the predictor and reponse variables\n",
                "x = heart_data.___.___\n",
                "\n",
                "#Remember to replace the string column values to 0 and 1\n",
                "y = heart_data.___.___.___\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Plot the predictor and reponse vairables as a scatter plot with axes label\n",
                "plt.scatter(___)\n",
                "plt.xlabel(___)\n",
                "plt.ylabel(___)\n",
                "plt.legend(loc='best')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Construct the components of our percpetron."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_affine) ###\n",
                "def affine(x, w, b):\n",
                "    \"\"\"Return affine transformation of x\n",
                "    \n",
                "    INPUTS\n",
                "    ======\n",
                "    x: A numpy array of points in x\n",
                "    w: A float representing the weight of the perceptron\n",
                "    b: A float representing the bias of the perceptron\n",
                "    \n",
                "    RETURN\n",
                "    ======\n",
                "    z: A numpy array of points after the affine transformation\n",
                "    \"\"\"\n",
                "    \n",
                "    # your code here\n",
                "    z = ___\n",
                "    return z"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_sigmoid) ###\n",
                "def sigmoid(z):\n",
                "    # hint: numpy has an exponentiation function, np.exp()\n",
                "    \n",
                "    # your code here\n",
                "    h = ___\n",
                "    return h"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_neuron_predict) ###\n",
                "def neuron_predict(x, w, b):\n",
                "    #Call the previous functions\n",
                "    \n",
                "    # your code here\n",
                "    h = ___\n",
                "    return h"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Manually set the weight and bias parameters. \n",
                "\n",
                "Recall from lecture that the weight changes the slope of the sigmoid and the bias shifts the function to the left or right."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hint: try values between -1 and 1\n",
                "w = ___ \n",
                "\n",
                "# Hint: try values between 50 and 100\n",
                "b = ___   "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Use the perceptron to make predictions and plot our results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The forward mode or predict of a single neuron\n",
                "\n",
                "# Create evenly spaced values of x to predict on\n",
                "x_linspace = np.linspace(x.min(),x.max(),500) \n",
                "h = neuron_predict(x_linspace,w, b)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot Predictions\n",
                "fig, ax = plt.subplots(1,1, figsize=(11,7))\n",
                "ax.scatter(x, y, label=r'Heart Data', alpha=0.2)\n",
                "ax.plot(x_linspace, h, lw=2, c='orange', label=r'Single Neuron')\n",
                "\n",
                "# first value in x_linspace with a probability \u003c 0.5\n",
                "db = x_linspace[np.argmax(h\u003c0.5)] \n",
                "ax.axvline(x=db, alpha=0.3, linestyle='-.', c='r', label='Decision Boundary')\n",
                "\n",
                "# Proper plot labels are very important!\n",
                "\n",
                "# Make the tick labels big enough to read\n",
                "ax.tick_params(labelsize=16)\n",
                "plt.xlabel('MaxHR', fontsize=16)\n",
                "plt.ylabel('Heart Disease (AHD)', fontsize=16)\n",
                "\n",
                "# Create a legend and make it big enough to read\n",
                "ax.legend(fontsize=16, loc='best') \n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "One way to assess our perceptron model's performance is to look at the binary cross entropy loss."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "def loss(y_true, y_pred, eps=1e-15):\n",
                "    assert y_true.shape[0] == y_pred.shape[0]\n",
                "    \n",
                "    # Clipping\n",
                "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
                "    return -sum(y_true*np.log(y_pred) + (1-y_true)*(np.log(1-y_pred)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "## Print the loss\n",
                "h = neuron_predict(x, w, b)\n",
                "print(loss(y, h))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To ensure our perceptron model is not trivial we need to compare its accuracy to a baseline which always predicts the majority class (i.e., no heart disease). Play with your weights above and rerun the notebook until you can outperform the baseline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "def accuracy(y_true, y_pred):\n",
                "    assert y_true.shape[0] == y_pred.shape[0]\n",
                "    return sum(y_true == (y_pred \u003e= 0.5).astype(int))/len(y_true)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_performance) ###\n",
                "\n",
                "# For the baseline predictions are all ones\n",
                "baseline_acc = accuracy(y, np.ones(len(y))) \n",
                "perceptron_acc = accuracy(y, h)\n",
                "print(f'Baseline Accuracy: {baseline_acc:.2%}')\n",
                "print(f'Perceptron Accuracy: {perceptron_acc:.2%}')"
            ]
        }
    ]
}
