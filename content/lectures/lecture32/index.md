Title: Lecture 32: Regularization methods - Weight decay, data augmentation and dropout
Category: lectures
Date: 2020-11-18
Author: Pavlos Protopapas
Slug: lecture32
Tags: Regularization, Neural Networks, Data Augmentation, Weight Decay, Dropout


## Slides
- [PDF | Lecture 32: Optimizers]({attach}slides/Lecture32_Optimizers.pdf)
- [PPTX | Lecture 32: Optimizers]({attach}slides/Lecture32_Optimizers.pptx)
- [PDF | Lecture 32: NN Regularization A]({attach}slides/Lecture32_NNRegularization-Part A.pdf)
- [PPTX | Lecture 32: NN Regularization A]({attach}slides/Lecture32_NNRegularization-Part A.pptx)
- [PDF | Lecture 32: NN Regularization B]({attach}slides/Lecture32_NNRegularization-part B.pdf)
- [PPTX | Lecture 32: NN Regularization B]({attach}slides/Lecture32_NNRegularization-part B.pptx)

## Exercises
- [Lecture 32: Regularization using L1 and L2 Norm [Notebook]]({filename}notebook/regularization_nn.ipynb)
- [Lecture 32: Early Stopping [Notebook]]({filename}notebook/early_stopping.ipynb)