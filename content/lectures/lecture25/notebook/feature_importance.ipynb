{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "\n",
    "**Exercise: Feature Importance**\n",
    "\n",
    "# Description\n",
    "\n",
    "The goal of this exercise is to compare two feature importance methods; MDI, and Permutation Importance. For a discussion on the merits of each <a href=\"https://scikit-learn.org/stable/modules/permutation_importance.html\" target=\"_blank\">see</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/image.png\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "- Read the dataset `heart.csv` as a pandas dataframe, and take a quick look at the data.\n",
    "- Assign the predictor and response variables as per the instructions given in the scaffold.\n",
    "- Set a max_depth value.\n",
    "- Define a `DecisionTreeClassifier` and fit on the entire data.\n",
    "- Define a `RandomForestClassifier` and fit on the entire data.\n",
    "- Calculate Permutation Importance for each of the two models. Remember that the MDI is automatically computed by sklearn when you call the classifiers.\n",
    "- Use the routines provided to display the feature importance of bar plots. The plots will look similar to the one given above.\n",
    "\n",
    "# Hints:\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html#\" target=\"_blank\">forest.feature_importances_</a> : Calculate the impurity-based feature importance.\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance\" target=\"_blank\">sklearn.inspection.permutation_importance()</a> : Calculate the permutation-based feature importance.\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" target=\"_blank\">sklearn.RandomForestClassifier()</a> : Returns a random forest classifier object.\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\" target=\"_blank\">sklearn.DecisionTreeClassifier()</a>: Returns a decision tree classifier object.\n",
    "\n",
    "NOTE - MDI is automatically computed by sklearn by calling RandomForestClassifier and/or DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from helper import plot_permute_importance, plot_feature_importance\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset and take a quick look\n",
    "\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the predictor and response variables.\n",
    "\n",
    "# 'AHD' is the response and all the other columns are the predictors\n",
    "X = ___\n",
    "y = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "\n",
    "# The random state is fized for testing purposes\n",
    "\n",
    "random_state = 44\n",
    "\n",
    "# Choose a `max_depth` for your trees \n",
    "\n",
    "max_depth = ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SINGLE TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_decision_tree) ###\n",
    "\n",
    "# Define a Decision Tree classifier with random_state as the above defined variable\n",
    "# Set the maximum depth to be max_depth\n",
    "\n",
    "tree = __\n",
    "\n",
    "# Fit the model on the entire data\n",
    "tree.fit(X, y);\n",
    "\n",
    "# Using Permutation Importance to get the importance of features for the Decision Tree \n",
    "# With random_state as the above defined variable\n",
    "\n",
    "tree_result = ___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_random_forest) ###\n",
    "\n",
    "# Define a Random Forest classifier with random_state as the above defined variable\n",
    "# Set the maximum depth to be max_depth and use 10 estimators\n",
    "\n",
    "forest = ___\n",
    "\n",
    "# Fit the model on the entire data\n",
    "\n",
    "forest.fit(X, y);\n",
    "\n",
    "# Use Permutation Importance to get the importance of features for the Random Forest model \n",
    "# With random_state as the above defined variable\n",
    "\n",
    "forest_result = ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOTTING THE FEATURE RANKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the helper code given to visualize the feature importance using 'MDI'\n",
    "\n",
    "plot_feature_importance(tree,forest,X,y);\n",
    "\n",
    "# Use the helper code given to visualize the feature importance using 'permutation feature importance'\n",
    "\n",
    "plot_permute_importance(tree_result,forest_result,X,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mindchow üç≤\n",
    "\n",
    "Q1. A common criticism for the MDI method is that it assigns a lot of importance to *noisy features* (more [here](https://arxiv.org/abs/1906.10845)). Did you make such an observation in the plots above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. After marking, change the `max_depth` for your classifiers to a very low value such as $3$, and see if you see a change in the relative importance of predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
