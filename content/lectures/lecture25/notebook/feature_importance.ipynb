{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import the necessary libraries\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.inspection import permutation_importance\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from helper import plot_permute_importance, plot_feature_importance\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read the dataset and take a quick look\n",
                "\n",
                "df = pd.read_csv(\"heart.csv\")\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Assign the predictor and response variables.\n",
                "\n",
                "# 'AHD' is the response and all the other columns are the predictors\n",
                "X = ___\n",
                "y = ___"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set the parameters\n",
                "\n",
                "# The random state is fized for testing purposes\n",
                "\n",
                "random_state = 44\n",
                "\n",
                "# Choose a `max_depth` for your trees \n",
                "\n",
                "max_depth = ___"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### SINGLE TREE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_decision_tree) ###\n",
                "\n",
                "# Define a Decision Tree classifier with random_state as the above defined variable\n",
                "# Set the maximum depth to be max_depth\n",
                "\n",
                "tree = __\n",
                "\n",
                "# Fit the model on the entire data\n",
                "tree.fit(X, y);\n",
                "\n",
                "# Using Permutation Importance to get the importance of features for the Decision Tree \n",
                "# With random_state as the above defined variable\n",
                "\n",
                "tree_result = ___\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### RANDOM FOREST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_random_forest) ###\n",
                "\n",
                "# Define a Random Forest classifier with random_state as the above defined variable\n",
                "# Set the maximum depth to be max_depth and use 10 estimators\n",
                "\n",
                "forest = ___\n",
                "\n",
                "# Fit the model on the entire data\n",
                "\n",
                "forest.fit(X, y);\n",
                "\n",
                "# Use Permutation Importance to get the importance of features for the Random Forest model \n",
                "# With random_state as the above defined variable\n",
                "\n",
                "forest_result = ___"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### PLOTTING THE FEATURE RANKING"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use the helper code given to visualize the feature importance using 'MDI'\n",
                "\n",
                "plot_feature_importance(tree,forest,X,y);\n",
                "\n",
                "# Use the helper code given to visualize the feature importance using 'permutation feature importance'\n",
                "\n",
                "plot_permute_importance(tree_result,forest_result,X,y);"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Mindchow üç≤\n",
                "\n",
                "Q1. A common criticism for the MDI method is that it assigns a lot of importance to *noisy features* (more [here](https://arxiv.org/abs/1906.10845)). Did you make such an observation in the plots above?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Q2. After marking, change the `max_depth` for your classifiers to a very low value such as $3$, and see if you see a change in the relative importance of predictors."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        }
    ]
}
